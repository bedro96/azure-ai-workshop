{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개요\n",
    "OpenAI 모델에 요청을 보낼 때 여러 매개변수를 사용하여 모델의 동작과 출력을 제어할 수 있습니다. \\\n",
    "이러한 매개변수를 이해하면 텍스트 생성, 질문 응답 또는 기타 사용 사례에 맞게 응답을 세부 조정할 수 있습니다.\n",
    "\n",
    "더 자세한 예제는 공식 문서를 참조하세요: [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  azure_ad_token_provider=token_provider,\n",
    "  api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "CHAT_COMPLETIONS_MODEL = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 매개변수: max_tokens\n",
    "**설명**: 생성할 응답의 최대 토큰 수를 설정합니다. \\\n",
    "**기본값**: 16 \\\n",
    "**예제**: max_tokens=50\n",
    "\n",
    "프롬프트의 토큰 수와 max_tokens의 합은 모델의 컨텍스트 길이를 초과할 수 없습니다. \\\n",
    "gpt-4o-mini의 경우 16,384 tokens이며 모델에 따라 다릅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens=max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Tokens: 32\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Max Tokens: 64\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Max Tokens: 120\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Max Tokens: 200\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def call_openai_with_max_tokens(max_tokens):\n",
    "    response = client.chat.completions.create(\n",
    "          model=CHAT_COMPLETIONS_MODEL,\n",
    "          messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": \"최고의 반려동물은 \"}],\n",
    "                     max_tokens=max_tokens\n",
    "                    \n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "tokens = [32, 64, 120, 200]\n",
    "for token in tokens:\n",
    "    print(f\"Max Tokens: {token}\\n\")\n",
    "    print(call_openai_with_max_tokens(token))\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 매개변수: temperature\n",
    "\n",
    "**설명**: 출력의 무작위성을 제어합니다. 낮은 값은 출력을 더 결정론적으로 만들고, 높은 값은 무작위성을 증가시킵니다. \\\n",
    "**값 범위**: 0에서 1 \\\n",
    "**기본값**: 1 \\\n",
    "**예제**: temperature=0.7\n",
    "\n",
    "높은 값은 모델이 더 창의적인 출력을 생성하도록 합니다. \\\n",
    "창의적인 응용 프로그램에는 0.9를, 명확한 답변이 필요한 경우에는 0(최대 확률 샘플링)을 시도하세요.\n",
    "\n",
    "---\n",
    "**참고**: 일반적으로 이 매개변수 또는 top_p를 조정하되 둘 다 동시에 조정하지 않는 것을 권장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(num_times, prompt, temperature=0.75, use_seed=False):\n",
    "    for i in range(num_times):\n",
    "        if use_seed:\n",
    "            response = client.chat.completions.create(\n",
    "                model=CHAT_COMPLETIONS_MODEL,\n",
    "                messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                            {\"role\":\"user\",\"content\": prompt}],\n",
    "                    max_tokens=60,\n",
    "                    seed=SEED,\n",
    "                    temperature = temperature\n",
    "            )\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "                model=CHAT_COMPLETIONS_MODEL,\n",
    "                messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                            {\"role\":\"user\",\"content\": prompt}],\n",
    "                    max_tokens=60,\n",
    "                    temperature = temperature\n",
    "            )\n",
    "        print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반려동물을 선택할 때 \"최고의\" 반려동물은 개인의 생활 방식, 취향, 필요에 따라 달라질 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 살펴보면 다음과 같습니다:\n",
      "\n",
      "1. **강아지\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물 옵션과 각각의 장점을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 사회적이고 충성스러운 동물로, 많은\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물 옵션과 각각의 장점을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 사회적이고 충성스러운 동물로, 많은\n",
      "최고의 반려동물은 개인의 생활 방식, 선호도, 필요에 따라 다릅니다. 어떤 사람들에게는 개가 최고의 반려동물이 될 수 있으며, 이는 그들이 동반자 관계와 활동적인 라이프 스타일을 즐기기 때문입니다. 다른\n",
      "최고의 반려동물은 개인의 생활 방식, 선호도, 필요에 따라 다릅니다. 어떤 사람들에게는 개가 최고의 반려동물이 될 수 있으며, 이는 그들이 동반자 관계와 활동적인 라이프 스타일을 즐기기 때문입니다. 다른\n",
      "최고의 반려동물은 개인의 생활 방식, 선호도, 필요에 따라 다릅니다. 다양한 반려동물 각각의 장점을 고려하여 선택하는 것이 중요합니다. 몇 가지 인기 있는 반려동물의 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개\n",
      "최고의 반려동물은 개인의 생활 방식, 선호도, 필요에 따라 다릅니다. 다양한 반려동물 각각의 장점을 고려하여 선택하는 것이 중요합니다. 몇 가지 인기 있는 반려동물의 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물 옵션을 고려해 보겠습니다:\n",
      "\n",
      "1. **개**: 개는 충성스럽고 사회적이며 다양한 품종이 있어 각\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물 옵션을 고려해 보겠습니다:\n",
      "\n",
      "1. **개**: 개는 충성스럽고 사회적이며 다양한 품종이 있어 각\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 다양한 반려동물이 각기 다른 장점과 요구 사항을 가지고 있기 때문에, 자신의 상황에 가장 적합한 반려동물을 선택하는 것이 중요합니다. 아래\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 다양한 반려동물이 각기 다른 장점과 요구 사항을 가지고 있기 때문에, 자신의 상황에 가장 적합한 반려동물을 선택하는 것이 중요합니다. 아래\n",
      "반려동물을 선택할 때 최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물 종류와 그 특성을 소개하겠습니다:\n",
      "\n",
      "1. **강아지**: 많은 사람들이 사랑하는 반려\n",
      "반려동물을 선택할 때 최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물 종류와 그 특성을 소개하겠습니다:\n",
      "\n",
      "1. **강아지**: 많은 사람들이 사랑하는 반려\n",
      "최고의 반려동물은 각 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개해 드리겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이\n",
      "최고의 반려동물은 각 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개해 드리겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이\n",
      "최고의 반려동물은 개인의 취향, 생활 방식, 그리고 특정 요구에 따라 다를 수 있습니다. 다양한 반려동물 중 몇 가지 인기 있는 선택지를 소개하겠습니다:\n",
      "\n",
      "1. **강아지**: 다양한 품종과 성격을 가진 강아\n",
      "최고의 반려동물은 개인의 취향, 생활 방식, 그리고 특정 요구에 따라 다를 수 있습니다. 다양한 반려동물 중 몇 가지 인기 있는 선택지를 소개하겠습니다:\n",
      "\n",
      "1. **강아지**: 다양한 품종과 성격을 가진 강아\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 장점을 소개하겠습니다.\n",
      "\n",
      "1. **개**: 충성심이 강하고 주인과의 유대가 깊\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 장점을 소개하겠습니다.\n",
      "\n",
      "1. **개**: 충성심이 강하고 주인과의 유대가 깊\n"
     ]
    }
   ],
   "source": [
    "# Without seed and temperature, the response is different each time\n",
    "call_openai(10, '최고의 반려동물은 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개해드리겠습니다.\n",
      "\n",
      "1. **강아지**: 강아지는 충성스럽고 사회적이며\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어 크기\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어 크기\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개해드리겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개해드리겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어 크기\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어 크기\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어 크기\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어 크기\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그들의 특징을 소개하겠습니다.\n",
      "\n",
      "1. **개**: 충성심이 강하고 사회적이며, 다양한 품종\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그들의 특징을 소개하겠습니다.\n",
      "\n",
      "1. **개**: 충성심이 강하고 사회적이며, 다양한 품종\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그들의 장점을 소개하겠습니다.\n",
      "\n",
      "1. **개**: 충성심이 강하고 사회적이며, 주인과\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그들의 장점을 소개하겠습니다.\n",
      "\n",
      "1. **개**: 충성심이 강하고 사회적이며, 주인과\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어 크기\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개하겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어 크기\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개해드리겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그 특징을 소개해드리겠습니다:\n",
      "\n",
      "1. **개**: 충성스럽고 사회적이며 다양한 품종이 있어\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그들의 특징을 소개하겠습니다.\n",
      "\n",
      "1. **개**: 충성심이 강하고 사회적이며, 다양한 품종\n",
      "최고의 반려동물은 개인의 생활 방식, 취향, 필요에 따라 다를 수 있습니다. 몇 가지 인기 있는 반려동물과 그들의 특징을 소개하겠습니다.\n",
      "\n",
      "1. **개**: 충성심이 강하고 사회적이며, 다양한 품종\n"
     ]
    }
   ],
   "source": [
    "# Now using a seed and 0 temperature, the response is the much more consisitent\n",
    "call_openai(10, '최고의 반려동물은 ', temperature = 0, use_seed=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 매개변수: n\n",
    "**설명**: 각 프롬프트에 대해 생성할 응답의 수를 지정합니다. \\\n",
    "**기본값**: 1 \\\n",
    "**예제**: n = 3 \n",
    "\n",
    "---\n",
    "**참고**: 이 매개변수는 여러 응답을 생성하므로 토큰 할당량을 빠르게 소모할 수 있습니다. 신중하게 사용하고 max_tokens 및 stop 설정이 적절한지 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1 ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "            model=CHAT_COMPLETIONS_MODEL,\n",
    "            messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                        {\"role\":\"user\",\"content\": \"최고의 반려동물은\"}],\n",
    "                max_tokens=60,\n",
    "                n=2\n",
    "        )\n",
    "\n",
    "for index, c in enumerate(response.choices):\n",
    "    print(index, c.message.content)\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 매개변수: presence_penalty\n",
    "**설명**: 텍스트에 이미 나타난 토큰을 기반으로 새 토큰에 페널티를 부여하여 모델이 새로운 토큰을 사용하도록 유도합니다. \\\n",
    "**값 범위**: -2.0에서 2.0 \\\n",
    "**기본값**: 0 \\\n",
    "**예제**: presence_penalty=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence Penalty: 0\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m penalty \u001b[38;5;129;01min\u001b[39;00m penalties:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPresence Penalty: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpenalty\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mcall_openai_with_presence_penalty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mcall_openai_with_presence_penalty\u001b[39m\u001b[34m(presence_penalty)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_openai_with_presence_penalty\u001b[39m(presence_penalty):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     response = \u001b[43mclient\u001b[49m.chat.completions.create(\n\u001b[32m      3\u001b[39m           model=CHAT_COMPLETIONS_MODEL,\n\u001b[32m      4\u001b[39m           messages = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m      5\u001b[39m                     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m최고의 반려동물은 \u001b[39m\u001b[33m\"\u001b[39m}],\n\u001b[32m      6\u001b[39m                     max_tokens=\u001b[32m60\u001b[39m,\n\u001b[32m      7\u001b[39m                     presence_penalty=presence_penalty, \n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m     )\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "def call_openai_with_presence_penalty(presence_penalty):\n",
    "    response = client.chat.completions.create(\n",
    "          model=CHAT_COMPLETIONS_MODEL,\n",
    "          messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": \"최고의 반려동물은 \"}],\n",
    "                    max_tokens=60,\n",
    "                    presence_penalty=presence_penalty, \n",
    "                    \n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Generate with different presence_penalty values\n",
    "penalties = [0, 0.5, 1.0, 1.5, 2.0]\n",
    "for penalty in penalties:\n",
    "    print(f\"Presence Penalty: {penalty}\\n\")\n",
    "    print(call_openai_with_presence_penalty(penalty))\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 매개변수: frequency_penalty\n",
    "**설명**: 텍스트에 이미 나타난 빈도를 기반으로 새 토큰에 페널티를 부여하여 동일한 줄을 반복할 가능성을 줄입니다. \\\n",
    "**값 범위**: -2.0에서 2.0 \\\n",
    "**기본값**: 0 \\\n",
    "**예제**: frequency_penalty=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 탐색할 사용 사례\n",
    "1. **응답 비교** \\\n",
    "여러 응답을 생성하여 사용 사례에 가장 적합한 응답을 선택하세요.\n",
    "\n",
    "2. **다양성 증가** \\\n",
    "다양한 응답을 얻기 위해 여러 응답을 생성하세요. 이는 창의적인 응용 프로그램에 유용합니다.\n",
    "\n",
    "3. **강건성 향상** \\\n",
    "여러 응답을 생성하여 일관성과 정확성을 보장하세요.\n",
    "\n",
    "#### 모범 사례\n",
    "1. **프롬프트 길이 최적화** \\\n",
    "프롬프트를 간결하지만 정보가 충분하도록 유지하여 모델이 충분한 컨텍스트를 가지도록 하세요.\n",
    "\n",
    "2. **Temperature 및 Top_p 조정** \\\n",
    "결정론적 응답과 창의적 응답 간의 균형을 맞추기 위해 이 매개변수를 사용하세요.\n",
    "\n",
    "3. **토큰 사용량 모니터링** \\\n",
    "max_tokens 매개변수를 신중히 설정하여 비용과 응답 길이를 관리하세요.\n",
    "\n",
    "4. **중지 시퀀스 사용** \\\n",
    "모델이 텍스트 생성을 중지해야 할 위치를 정의하여 원하는 컨텍스트 내에서 출력을 제어하세요.\n",
    "\n",
    "5. **여러 응답 생성** \\\n",
    "n 매개변수를 사용하여 여러 응답을 생성하고 필요에 가장 적합한 응답을 선택하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
